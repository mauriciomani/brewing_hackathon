{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Logistics Problems\n",
    "We have to deliver products over the week the **6 days**, then we have to define 6 zones from given place from the **path_source**, however the solution is not that easy, we have some constraints. The stops and distribution of items needs to be balanced. Then we will combine **Constrained Kmeans** and **Integer Programming** (IP) or **Mixed Integer Linear Programming** (MILP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pulp\n",
    "#for haversine distance\n",
    "from math import radians\n",
    "#calculate distance matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from k_means_constrained import KMeansConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cplex = \"/opt/ibm/ILOG/CPLEX_Studio1210/cplex/bin/x86-64_linux/cplex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_milp = \"milp_solution.csv\"\n",
    "path_ip = \"ip_solution.csv\"\n",
    "path_source = \"ubicaciones.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are some values with no volume of delivery but they do have frequency, then we need to go through \n",
    "Those values that have no items to deliver will deliver 0.00001 items to be taken into account in the LP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[df[\"Vol_Entrega\"] == 0].index, \"Vol_Entrega\"] = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the 6 working days of the week\n",
    "zones = [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\"]\n",
    "agencies = list(\"A\" + df[\"Id_Cliente\"].astype(str))\n",
    "vol_delivery = list(df[\"Vol_Entrega\"])\n",
    "vol_stores = list(df[\"Vol_Entrega\"]*df[\"Frecuencia\"])\n",
    "frequency = list(df[\"Frecuencia\"])\n",
    "stores_volume = dict(zip(agencies, vol_stores))\n",
    "stores_frequency = dict(zip(agencies, frequency))\n",
    "vol_delivery = dict(zip(agencies, vol_delivery))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9066.66681333136"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vol_stores)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662.8333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(frequency)/6\n",
    "#df.shape[0]/6 # for balanced kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stops_gap(per):\n",
    "    \"\"\"\n",
    "    Calculates the deviation in the stops. Numbers from cells above\n",
    "    Args:\n",
    "        per : Percentage of deviation from balanced stops\n",
    "    Returns:\n",
    "        upper : Upper bound\n",
    "        lower : Lower bound\n",
    "    \"\"\"\n",
    "    upper = int(663 + (663 * per))\n",
    "    lower = int(662 - (662 * per))\n",
    "    return(upper, lower)\n",
    "\n",
    "def items_gap(per):\n",
    "    \"\"\"\n",
    "    Calculates the deviation in the items distributed or flow. Numbers from cells above.\n",
    "    Args:\n",
    "        per : Percentage of deviation from distribution\n",
    "    Returns:\n",
    "        upper : Upper bound\n",
    "        lower : Lower bound\n",
    "    \"\"\"\n",
    "    upper = int(9067 + (9067 * per))\n",
    "    lower = int(9066 - (9066 * per))\n",
    "    return(upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lat_radians\"] = df[\"lat\"].apply(lambda x: radians(x))\n",
    "df[\"lon_radians\"] = df[\"lon\"].apply(lambda x: radians(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "fitted_scaler = scaler.fit(df[[\"lat\", \"lon\"]])\n",
    "scaled_coordinates = fitted_scaler.transform(df[[\"lat\", \"lon\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Kmeans vs. Balanced Kmeans\n",
    "I have found using Balanced Kmeans is way better and results were good even without LP, IP or MILP optimization. It ss weight less complex than what we are doing below. I also think there might be other interesting ways of selecting centroids or trying to iterate and find minimum distances.<br>\n",
    "We could implement a Kmeans were once the data constraints have been met, go to next cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeansConstrained(n_clusters=6,\n",
    "                           size_min=600,\n",
    "                           size_max=609,\n",
    "                           random_state=12,\n",
    "                           n_init=100,\n",
    "                           max_iter=200,\n",
    "                           n_jobs = -1)\n",
    "kmeans_values = kmeans.fit(scaled_coordinates)\n",
    "df[\"kmeans\"] = list(kmeans.predict(scaled_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans = KMeans(n_clusters = 6, random_state = 2020, init=\"random\")\n",
    "#kmeans_values = kmeans.fit_predict(scaled_coordinates, sample_weight=df[\"Vol_Entrega\"])\n",
    "#df[\"kmeans\"] = list(kmeans_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_lat_lon = df[[\"lat\", \"lon\"]].to_numpy()\n",
    "#for haversine distance\n",
    "#vectorized_lat_lon = df[[\"lat_radians\", \"lon_radians\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = fitted_scaler.inverse_transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance metrics (for more information give a look at README)\n",
    "* Manhattan distance, also known as cityblock, largest distance.\n",
    "* Euclidean, very common will not talk about it.\n",
    "* Haversine distance, we are able to get km distance and works better for larger distances. However did not worked quiet properly on this specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = cdist(cluster_centers, vectorized_lat_lon, metric= \"euclidean\")\n",
    "#distance_matrix = haversine_distances(cluster_centers, vectorized_lat_lon) * (6371000/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all possible routes\n",
    "routes = [(z, a) for z in zones for a in agencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pulp.makeDict([zones, agencies], distance_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = pulp.LpVariable.dicts(\"Distribution\", (zones, agencies), 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same using either LpBinary or LpInteger\n",
    "using = pulp.LpVariable.dicts(\"BelongstoZone\", (zones, agencies), 0, 1, pulp.LpInteger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pulp.LpProblem(\"BrewingDatCup2020_v1\", pulp.LpMinimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob += pulp.lpSum([distances[z][a] * flow[z][a]  for (z, a) in routes]) + pulp.lpSum([distances[z][a] * using[z][a]  for (z, a) in routes]), \"totalCosts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in zones:\n",
    "    prob += pulp.lpSum([using[z][a] for a in agencies]) <= 713, \"SumStopsInZoneUpper %s\"%z\n",
    "    prob += pulp.lpSum([using[z][a] for a in agencies]) >= 612, \"SumStopsInZoneLower %s\"%z\n",
    "    prob += pulp.lpSum([flow[z][a] for a in agencies]) <= 9748, \"SumDistrInZoneUpper %s\"%z\n",
    "    prob += pulp.lpSum([flow[z][a] for a in agencies]) >= 8386, \"SumDistrInZoneLower %s\"%z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in zones:\n",
    "    for a in agencies:\n",
    "        prob += flow[z][a]-(100000*using[z][a]) <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in zones:\n",
    "    for a in agencies:\n",
    "        prob += flow[z][a] <= vol_delivery[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each equation its an agency\n",
    "for a in agencies:\n",
    "    prob += pulp.lpSum([flow[z][a] for z in zones]) >= stores_volume[a], \"Distribution %s\"%a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in agencies:\n",
    "    prob += pulp.lpSum([using[z][a] for z in zones]) == stores_frequency[a], \"FrequencyDistribution %s\"%a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you got infeasability problems check your constraints\n",
    "#https://coin-or.github.io/pulp/guides/how_to_configure_solvers.html\n",
    "prob.writeLP(\"milp_brewing.lp\")\n",
    "solver = pulp.CPLEX_CMD(path=path_to_cplex)\n",
    "prob.solve(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado:  Optimal\n",
      "Total Cost:  1752.5996784102415\n"
     ]
    }
   ],
   "source": [
    "print(\"Estado: \", pulp.LpStatus[prob.status])\n",
    "print(\"Total Cost: \", pulp.value(prob.objective))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive best solution\n",
    "According to the given function to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563.6223089057698"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(distance_matrix.T.min(1) * vol_stores) + sum(distance_matrix.T.min(1) * frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPLEX Optimal Solutions\n",
    "Estado:  Optimal (Extremely Balanced: 663 stops & 9067 items) <br>\n",
    "Total Cost:  1783.0206990091006\n",
    "<br>\n",
    "<br>\n",
    "Estado:  Optimal (10% balanced) <br>\n",
    "Total Cost:  1748.4626671795415\n",
    "<br>\n",
    "<br>\n",
    "Estado:  Optimal (7.5% balanced) <br>\n",
    "Total Cost:  1752.5996784102415\n",
    "<br>\n",
    "<br>\n",
    "Estado:  Optimal (5% balanced) <br>\n",
    "Total Cost:  1758.3484761963682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why using CPLEX \n",
    "Other solutions such as Pulp_CBC_CMD where ran for over 20 hours without being able to solve it. I have to add that there are easier ways to solve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\"], index=(range(1, 3626)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_distr = dict()\n",
    "for v in prob.variables():\n",
    "    if (v.name).find(\"BelongstoZone_\")==0:\n",
    "        if v.varValue > 0:\n",
    "            dist = v.name[14:]\n",
    "            zone = dist[:2]\n",
    "            id_cliente = int(dist[4:])\n",
    "            final_df.loc[id_cliente, zone] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna(0, inplace = True)\n",
    "final_df = final_df.astype(int).reset_index().rename(columns = {\"index\":\"Id_Cliente\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(path_milp, header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Integer Programming\n",
    "Instead of adding a linking constraint, the way was donde above, multiply the binary value by the items to distribute and subject it to the max amount of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pulp.LpProblem(\"BrewingDatCup2020_v2\", pulp.LpMinimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob += pulp.lpSum([distances[z][a] * using[z][a]  for (z, a) in routes]), \"totalCosts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in agencies:\n",
    "    prob += pulp.lpSum([using[z][a] for z in zones]) == stores_frequency[a], \"FrequencyDistribution %s\"%a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_stop, lower_stop = stops_gap(0.005)\n",
    "upper_distr, lower_distr = items_gap(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in zones:\n",
    "    prob += pulp.lpSum([using[z][a] for a in agencies]) <= upper_stop, \"SumStopsInZoneUpper %s\"%z\n",
    "    prob += pulp.lpSum([using[z][a] for a in agencies]) >= lower_stop, \"SumStopsInZoneLower %s\"%z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in zones:\n",
    "    prob += pulp.lpSum([using[z][a] * vol_delivery[a] for a in agencies]) <= upper_distr, \"SumDistrInZoneUpper %s\"%z\n",
    "    prob += pulp.lpSum([using[z][a] * vol_delivery[a] for a in agencies]) >= lower_distr, \"SumDistrInZoneLower %s\"%z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you got infeasability problems check your constraints\n",
    "#https://coin-or.github.io/pulp/guides/how_to_configure_solvers.html\n",
    "prob.writeLP(\"ip_brewing.lp\")\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado:  Optimal\n",
      "Total Cost:  90.23376746026902\n"
     ]
    }
   ],
   "source": [
    "print(\"Estado: \", pulp.LpStatus[prob.status])\n",
    "print(\"Total Cost: \", pulp.value(prob.objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = [\"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\"], index=(range(1, 3626)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_distr = dict()\n",
    "for v in prob.variables():\n",
    "    if (v.name).find(\"BelongstoZone_\")==0:\n",
    "        if v.varValue > 0:\n",
    "            dist = v.name[14:]\n",
    "            zone = dist[:2]\n",
    "            id_cliente = int(dist[4:])\n",
    "            final_df.loc[id_cliente, zone] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna(0, inplace = True)\n",
    "final_df = final_df.astype(int).reset_index().rename(columns = {\"index\":\"Id_Cliente\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(path_ip, header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check constrained_kmeans notebook to test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 1, 5, 3, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If problem in logic please test this\n",
    "(np.argsort(distance_matrix.T))[1828]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further work\n",
    "* Better way of measuring distances, for example TSP or mean centroid-agencies.\n",
    "* Try different clustering constraints and seeds to see if improvements on score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
